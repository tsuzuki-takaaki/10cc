- つ
    - raxとeaxについて
    - > 64ビットCPUにおける「EAX」とは、RAXに使っているレジスタの下位32ビットのことである。けっして、RAXレジスタとは別にEAXレジスタが用意されているわけではない[9]。
    - https://ja.wikibooks.org/wiki/X86%E3%82%A2%E3%82%BB%E3%83%B3%E3%83%96%E3%83%A9/x86%E3%82%A2%E3%83%BC%E3%82%AD%E3%83%86%E3%82%AF%E3%83%81%E3%83%A3


https://www.sigbus.info/compilerbook

- commit tree: https://github.com/rui314/chibicc/commits/main?after=90d1f7f199cc55b13c7fdb5839d1409806633fdb+300&branch=main
- こっち？: https://github.com/rui314/chibicc/commit/97a255d2d33e76c0be672cc4ecd32f9035e833ca

入力を受け取りそれをC言語で処理をしてアセンブリを生成する

↑ これがコンパイラ(アセンブルとかリンクは入ってない)
- Rui ueyama: 受け取った文字列のポインタを進める, 次のtokenはメンバ変数にポインタとしてもつ
- Go言語で作るインタプリタ: whitespaceを区切りにしてそれぞれをTokenの構造体にしてる. tokenは入れ子構造になっている

## macOS static linking
static linkはサポートされてない

https://developer.apple.com/forums/thread/706419

## クロスコンパイラ
> コンパイラが動作するマシンのことを「ホスト」、コンパイラが出力したコードが動作するマシンのことを「ターゲット」といいます。

↑ `wasm32-unknown-unknonw`とかはまさにこの例で、ホストがunknownでターゲットもunknownであることを示している

> ホストとターゲットが異なるコンパイラのことをクロスコンパイラといいます。

## compielr of compiler
>コラム: コンパイラをコンパイルするコンパイラ
>
>**CコンパイラがCで書かれているといった自己参照的な状況は珍しくありません**。C以外でも、数多くの言語実装がその言語自体を使って書かれています。
>
>すでに言語Xの実装がある場合、その言語自身を使って新たなXコンパイラを作ることに論理的な矛盾はありません。もしセルフホストをしようと思ったら、単に既存のコンパイラで開発を進めていって、自作のものが完成したらスイッチすればよいだけです。この本で我々が行おうとしているのはまさにその方法です。
>
> **しかし既存のコンパイラがない場合はどうすればよいのでしょうか？ そのときには別の言語を使って書くしかありません。セルフホストするつもりでX言語の最初のコンパイラを書くときには、Xと異なる既存のY言語を使って書き、コンパイラの完成度が高まったところで、コンパイラ自身をY言語からX言語に書き直す必要があります。**
>
>**現代の複雑なプログラミング言語のコンパイラも、その言語の実装をコンパイルするために使った別のコンパイラ、というように系譜をさかのぼっていくと、最終的に、コンピュータの黎明期に誰かが機械語で直接書いた単純なアセンブラにたどりつくはずです**。現存するすべての言語実装のある意味の究極の祖先にあたるそのアセンブラが、単一なのか複数あったのかはわかりませんが、現在のコンパイラがごく少数の祖先から出発しているのは間違いないでしょう。コンパイラ以外の実行ファイルも普通はコンパイラが生成したファイルですから、現存するほぼすべての実行ファイルは、その原始のアセンブラの間接的な子孫にあたるわけです。これは生命の起源のような面白い話ですね。

### memory
>**CPUが実行するプログラムと、そのプログラムが読み書きするデータは、どちらもメモリに入っています**。CPUは「現在実行中の命令のアドレス」をCPU内部に保持していて、そのアドレスから命令を読み出して、そこに書かれていることを行い、そして次の命令を読み出して実行する、ということを行なっています。その**現在実行中の命令のアドレスのことをプログラムカウンタ（PC）やインストラクションポインタ（IP）といいます**。CPUが実行するプログラムの形式そのもののことを「機械語」(machine code)といいます。

### register
>CPUは**プログラムカウンタのほかにも**、少数のデータ保存領域を持っています。例えばIntelやAMDのプロセッサには、64ビット整数が保持できる領域が16個あります。この領域のことを「レジスタ」（register）と呼びます。メモリはCPUから見て外部の装置で、それを読み書きするには多少の時間がかかりますが、レジスタはCPU内部に存在していて、遅延なしにアクセスすることができます。

### CPU Architecture
>特定の機械語の命令を総称として「命令セットアーキテクチャ」（instruction set architecture, ISA）あるいは「命令セット」といいます。命令セットは一種類というわけではなく、CPUごとに好きにデザインしてかまいません。とはいえ、機械語レベルの互換性がないと同じプログラムを動かせないので、命令セットのバリエーションはそれほど多くありません。PCでは、Intelやその互換チップメーカーであるAMDの、x86-64と呼ばれる命令セットが使われています。x86-64は主要な命令セットの1つですが、x86-64だけが市場を独占しているというわけではありません。例えばiPhoneやAndroidではARMという命令セットが使われてます。

### objdump
↑ オブジェクトファイルの情報を表示する

```terminal
  $ objdump -d -M intel /bin/ls
```
↑ intelつけなかったら```AT&T```
- ```-d```: disassemble
```
  -M <value>              Alias for --disassembler-options=
```

### object codeのおさらい
ソースコードをコンパイル => ```object code```

↑ これだけでは実行できない
-> リンクする必要がある
-> リンクすると実行ファイルができあがる

↑ CとかRustだと自動的にリンカーが呼び出されてリンクされてる
-> 静的ライブラリとか共有ライブラリがある(linuxの仕組み)

### intel表記

```
  3d58:  48 83 ec 08           sub    rsp,0x8
```
- ```3d58```というのは、機械語が入っているメモリのアドレス
    - プログラムカウンタが0x3d58のときにこの命令が実行される
- ```48 83 ec 08```(16)は、実際の機械語
- RSPというレジスタから8を引く（subtract = 引く）という命令です。
    - AT&Tとは逆になる

### AT&T, Intel

https://qiita.com/edo_m18/items/83c63cd69f119d0b9831

### レジスタについて

https://github.com/tsuzuki-takaaki/concurrent_parallel/blob/main/3/README.md

### アセンブリ -> バイトコード
```
  cc -o output_file assembly_file.s
```

### 関数呼び出し
>関数呼び出しは単なるジャンプとは異なり、呼び出した関数が終了した後に、元々実行していた場所に戻ってこなければいけません。

```.c
    int plus(int x, int y) {
      return x + y;
    }
    
    int main() {
      return plus(3, 4);
    }
```
```.s
  .intel_syntax noprefix
  .globl plus, main

  plus:
          add rsi, rdi
          mov rax, rsi
          ret

  main:
          mov rdi, 3 # <- 第1引数
          mov rsi, 4 # <- 第2
          call plus
          ret
```
```ret```と```call```は対になってる

### Cのtips
#### 引数
https://www.ritsumei.ac.jp/~mmr14135/johoWeb/cmnds.html
```c
  int main(int argc, char **argv)
```
↑　の引数```argc```, ```**argv```は何を表してる？
- argc: コマンドライン引数の数
- argv: コマンドライン引数が文字列配列として格納される
```
  ./a.out 100 abc
```
このようなコマンドで実行された時
↓
```
argc=3; コマンドライン引数の数
argv[0]="./a.out";
argv[1]="100";
argv[2]="abc";
```

#### strtol
文字列を整数型の数値に変換
```c
  strtol(const char *nptr, char **endptr, int base);
```
>第一引数nptrに指定された文字列を第三引数baseで指定された基数で変換します。文字列の途中で変換が失敗した場合、その途中位置へのアドレスが、第二引数endptrが指すポインタへと格納されます。

>strtolは数値を読み込んだ後、第2引数のポインタをアップデートして、読み込んだ最後の文字の次の文字を指すように値を更新します。したがって、数値を1つ読み込んだ後、もしその次の文字が+や-ならば、pはその文字を指しているはずです。

#### メンバ変数アクセス
> メンバ変数にアクセスするためには、その変数が所属している構造体のインスタンス（オブジェクト）を持っている必要があります。また、ポインタを介してメンバ変数にアクセスする場合は、アロー演算子（->）を使用します。

#### va_list

https://qiita.com/kurasho/items/1f6e04ab98d70b582ab7#va_list%E3%81%AE%E4%B8%AD%E8%BA%AB

#### {シングル, ダブル} quote

https://masudahp.web.fc2.com/cl/kiso/ck0202.html

#### プロトタイプ宣言

https://webkaru.net/clang/function-declaration-prototypes/

> 複数のファイルで関数を共有する場合にも、関数宣言が必要となる.

&&

> Cでは、1つのファイルに全部の関数をまとめて書くときでも、宣言が必要になることがあります。Cの言語仕様では、コンパイラがファイル全体を読み込むことをせずに、関数1つ1つを先頭から順にコンパイルしていけるようになっています。したがって、どの関数も、その関数がファイル中で出現するところまでに書かれた情報だけでコンパイルできるようになっていなければいけません。従って、ファイルの後ろで定義されている関数を使いたい場合、事前にその関数の宣言を書いておく必要があります。そういった宣言のことを「前方宣言」（forward declaration）といいます。

↑ 前に定義している必要がある(が、関数の中身までは知る必要はない)

#### プロトタイプ宣言と.hファイルのinclude

> **インクルードされたヘッダーファイル内には、関数のプロトタイプ宣言（関数のシグネチャや戻り値の型など）が含まれることが一般的です**。このプロトタイプ宣言によって、他のファイルからその関数を使用する際には、関数の存在や引数の型、戻り値の型などが事前に宣言されていることが保証されます。具体的な関数の実装（定義）は、通常はソースコードファイルに記述されます。

↓

他のファイルからも使うなら関数の引数・戻り値の型を.hファイルに記述して、内部実装は他のファイルにする
(別ファイルで使わない場合も、わかりやすいように使ったりするから注意)


### gcc, cc
>Unixにおいてはcc（あるいはgcc）は、CやC++だけではなく多くの言語のフロントエンドということになっていて、**与えられたファイルの拡張子で言語を判定してコンパイラやアセンブラを起動する**ということになっています。したがってここでは9ccをコンパイルしたときと同じように、.sという拡張子のアセンブラファイルをccに渡すと、アセンブルをすることができます。

↑ v8のjavascriptとwasmのどっちもいけるのと同じかも？


#### memcmp

https://bituse.info/c_func/55

### BNF（Backus–Naur Form）, EBNF（Extended BNF）
↑ 記法の話(構文解析自体ではない)

>それ以上展開できない記号を「終端記号」（terminal symbol）、どれかの生成規則の左辺に来ていて展開できる記号を「非終端記号」（nonterminal symbol）といいます。このような生成規則で定義される文法のことを一般に「文脈自由文法」（context free grammar）といいます。

↑ 非終端記号は、さらに別のプロダクション規則に展開される可能性がある記号であり、終端記号は具体的な文字やトークンを表します。
ex: 
```
  <expression> ::= <term> "+" <expression>
  <term> ::= <factor> "*" <term>
  <factor> ::= "(" <expression> ")" | <number>
  <number> ::= "0" | "1" | "2" | ...
```
- 非終端記号: ```<expression>、<term>、<factor>、<number>```
- 終端記号: ```+、*、(、)、数値、文字列```

<br />

- 正規表現的な使い方？ができる
```A = ("fizz" | "buzz")*```では、Aは、"fizz"または"buzz"が0回以上繰り返された文字列、すなわち、
    - ""
    - "fizz"
    - "buzz"
    - "fizzfizz"
    - "fizzbuzz"
    - "buzzfizz"
    - "buzzbuzz"
    - "fizzfizzfizz"
    - "fizzfizzbuzz
    - ...

のいずれかに展開することができます。

```
  expr = num ("+" num | "-" num)*
```

↓ 末端nodeが終端記号

![スクリーンショット 2023-06-17 15.37.27.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2849988/564db6d9-af0f-a56a-8ea6-83e89ba5c0c1.png)

- 加減乗除の優先順位を表現する

```
  expr = mul ("+" mul | "-" mul)*
  mul  = num ("*" num | "/" num)*
```

>exprはmulを経由してnumに展開されるルールになりました。mulというのが乗除算の生成規則で、加減算を行うexprは、mulをいわば一つの部品として使っています。この文法では乗除算が先にくっつくというルールが構文木の中で自然と表現されることになります。

![スクリーンショット 2023-06-17 15.56.11.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2849988/db83a86f-6d86-a396-0578-3885285971e8.png)

↑ 
```mul  = num ("*" num | "/" num)*```の```("*" num | "/" num)*```の部分は0以上なので0でもOK
-> 1*2+3の例だと3の部分は```mul = num```の状態になっている

- 再帰を含む生成規則(```(```, ```)```を使う)
```
  expr    = mul ("+" mul | "-" mul)*
  mul     = primary ("*" primary | "/" primary)*
  primary = num | "(" expr ")"
```

↑ この例だとnumと(expression)が同じレベルにある(expression)の場合は再帰になる

![スクリーンショット 2023-06-17 16.08.26.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2849988/927f234b-3581-fa6e-4934-a8b03151e749.png)

### 再帰下降構文分析法
> **形式文法の各規則に対して対応する再帰的な手続き(関数)を定義**し、トークン列を解析して構文木を構築します。

--- 「Go言語で作るインタプリタ」の```トップダウン演算子優先順位構文解析(Pratt構文解析)```の場合は、BNFやEBNFで定義される文法ルールに関連づけるのではなく、トークンタイプに関連付けして実装されてる.

> 1. 形式文法を用意します。この文法は通常、BNF（Backus-Naur Form）などの形式で表現されます。
> 2. **文法の<font color=red>非</font>終端記号に対応する再帰的な手続き（関数）を定義**します。各非終端記号には、その規則に従って処理を行う手続きが対応します。
> 3. トークン列を読み取りながら、再帰的な手続きを呼び出して構文解析を進めます。各非終端記号に対して、対応する手続きが呼び出されます。手続き内では、トークンのマッチングや子ノードの構築、再帰呼び出しなどが行われます。
> 4. 手続きの実行中に構文エラーが発生した場合、構文解析は失敗となります。エラー処理が必要な場合は、適切なエラー処理ルーチンを追加することができます。
> 5. 構文解析が成功した場合、構文木が構築されます。構文木は通常、抽象構文木（Abstract Syntax Tree）として表現され、後続の処理（意味解析やコード生成など）に使用されます。


```
  expr    = mul ("+" mul | "-" mul)*
  mul     = primary ("*" primary | "/" primary)*
  primary = num | "(" expr ")"
```
これらの非終端記号一つ一つをそのまま関数一つ一つにマッピングする.したがってパーサはexpr、mul、primaryという3つの関数を持つことになります。

- ref
> 左から計算しなければならない演算子のことを「左結合」の演算子、右から計算しなければならない演算子のことを「右結合」の演算子といいます。Cでは、代入の=を除いて、ほとんどの演算子は左結合として定義されています。

### LL・LR

>**トークンを1つだけ先読みして**、どの関数を呼び出すか、あるいはリターンするか、ということを決めていましたが、そのようにトークンを1つだけ先読みする再帰下降パーサのことをLL(1)パーサといいます。また、LL(1)パーサが書ける文法のことをLL(1)文法といいます。

```LL（Left-to-Right, Leftmost derivation）``` or ```LR（Left-to-Right, Rightmost derivation）```

※ from ChatGPT

- LL
> LL文法解析（左再帰下降解析）：
>
> - LLは、左から右へトークンを読み込み、最も左の導出を構築する方法です。
> - LL構文解析は再帰的な下降構文解析法（recursive descent parsing）としても知られています。
> - LL構文解析では、トークン列を先読みして予測し、適切な文法規則を選択します。
> - LL構文解析は、一般に文法が左再帰でない（左再帰を持たない）場合に使用されます。
> - LL文法解析は通常、再帰的な関数のセットとしてプログラムされます。

- LR
> LR文法解析（左から右への最右導出）：
>
> - LRは、左から右へトークンを読み込み、最右の導出を構築する方法です。
> - LR構文解析は、スタックを使用して文法の規則を適用し、文法の右辺を逆順にスタックに積むことによって処理を行います。
> - LR構文解析は、一般に文法がより強力で、多くの文法クラスをサポートすることができます。
> - LR文法解析は、LR(0)、SLR(1)、LALR(1)、およびLR(1)などの異なるサブクラスに分類されることがあります。
> - LR構文解析は、パーサジェネレータ（パーサ生成ツール）を使用して自動的に生成されることが一般的です。

### スタックマシン
> スタックマシンは、スタックをデータ保存領域として持っているコンピュータのことです。

> スタックマシンでは、部分式を計算すると、それが何であれその結果の1つの値がスタックトップに残る

![スクリーンショット 2023-06-17 19.38.05.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2849988/ef1c2e18-0a03-6654-cb31-b13e86c37045.png)

>1のコードを実行した後には、その具体的なコードが何であれ、左の部分木の結果を表す1つの値がスタックトップに置かれているはずです。同様に、2のコードを実行した後には、右の部分木の結果を表す1つの値がスタックトップに置かれているはずです。したがって、木全体の値を計算するためには、その2つの値を、その合計値で置き換えればよいというわけです。

↓

このように、抽象構文木をスタックマシンにコンパイルするときは、再帰的に考えて、木を下りながらどんどんアセンブリを出力していくことになります。

よくある再帰の例
```rb
  n = gets.to_i

  def fibonacci(i)
    return 1 if i == 1 || i == 2
    return fibonacci(i - 1) + fibonacci(i - 2)
  end

  puts fibonacci(n)
```

- スタックの例(```2 + 3 * 4```)

![スクリーンショット 2023-06-17 19.47.22.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2849988/bc15e55d-9317-e601-980a-4c893bcdb721.png)

>コード生成を行う関数は木のルートのノードを受け取ります。
>
> 上記の手順に従うと、その関数がまず行うのは<font color=red>左</font>の部分木をコンパイルすることです。つまり数値の2をコンパイルすることになります。2を計算した結果はそのまま2なので、その部分木のコンパイル結果はPUSH 2です。
>
> 次にコード生成関数は右の部分木をコンパイルしようとします。そうすると再帰的に部分木の左側をコンパイルすることになり、結果としてPUSH 3が出力されます。次は部分木の右側をコンパイルすることになり、PUSH 4が出力されます。
> 
> そのあとコード生成関数は再帰呼び出しを元に戻りながら、部分木の演算子の型に合わせたコードを出力していきます。最初に出力されるのは、スタックトップの2つの要素を、それらを掛けたもので置き換えるコードです。その次にスタックトップの2つの要素を、それらを足したもので置き換えるコードが出力されます。結果として下のアセンブリが出力されることになります。
```
PUSH 2
PUSH 3
PUSH 4
MUL
ADD
```

-> このような手順で抽象構文木をアセンブリに落としていくことができる


### スタックマシン・レジスタマシン

http://fe0km.blog.fc2.com/blog-entry-106.html

> ```x86-64```はスタックマシンではなくレジスタマシンです。x86-64の演算は通常2つのレジスタ間に対して定義されており、スタックトップの2つの値に対して動作するように定義されているわけではありません.

>スタックマシンのテクニックをx86-64で使うためには、レジスタマシンでスタックマシンをある意味でエミュレートする必要があります。
>
>レジスタマシンでスタックマシンをエミュレートするのは比較的簡単です。スタックマシンで1命令になっているものを複数の命令を使って実装すればよいのです。

↓ **ここでスタックポインタとかベースポインタが出てくる**

### あえて冗長に書くアセンブリ
- ```2*3+4*5```を```x86-64```で
```
  // 2*3を計算して結果をスタックにプッシュ
  push 2
  push 3

  pop rdi        <- mov rdi, 3
  pop rax        <- mov rax, 2
  mul rax, rdi
  push rax

  // 4*5を計算して結果をスタックにプッシュ
  push 4
  push 5

  pop rdi
  pop rax
  mul rax, rdi
  push rax

  // スタックトップの2つの値を足す
  // つまり2*3+4*5を計算する
  pop rdi
  pop rax
  add rax, rdi
  push rax
```

もっと簡単に書けるところがいくつかある

↓

> 冗長さを取り除いて最適化したいという気持ちが湧き上がってきている人もいることでしょう。しかし、その誘惑には負けないようにしてください。一番最初のコード生成では、コンパイラの実装の容易さを優先して冗長なコードを出力するのは、望ましいことなのです。
>
> 生成されたアセンブリを再度スキャンして、特定のパターンで現れている命令列を別の命令列で置き換えることは難しくありません。
> 例えば「push直後のpopはmovに置き換える」とか「連続しているaddが、即値（そくち）を同じレジスタに足している場合、その即値を合計した値を足す1つのaddに置き換える」といったルールを作って、それを機械的に適用すれば、冗長なコードを、意味を変えることなくより効率的なコードに置き換えることができます。
> 
> コード生成と最適化を混ぜてしまうとコンパイラが複雑になってしまいます。最初から難しいコードになってしまうと、後から最適化パスを足すのはむしろ困難です。Donald Knuthが言っていたように「早すぎる最適化は全ての悪の元凶」なのです。読者の皆さんが作成するコンパイラでも、実装の簡単さだけを考慮するようにしてください。

- idiv
> idivは符号あり除算を行う命令です。x86-64のidivが素直な仕様になっていれば、上のコードでは本来idiv rax, rdiのように書きたかったところですが、そのような**2つのレジスタをとる除算命令はx86-64には存在しません**。
>その代わりに、idivは暗黙のうちにRDXとRAXを取って、それを合わせたものを128ビット整数とみなして、それを引数のレジスタの64ビットの値で割り、商をRAXに、余りをRDXにセットする、という仕様になっています。cqo命令を使うと、RAXに入っている64ビットの値を128ビットに伸ばしてRDXとRAXにセットすることができるので、上記のコードではidivを呼ぶ前にcqoを呼んでいます。

### garbage collection
今回はcallocしているのに、freeをしてない

> freeをしないことによって発生する問題というのは、普通のPCのようなコンピュータで動かすことを考えると、実質的にあまり存在しません。コンパイラは1つのCファイルを読み込んでアセンブリを出力するだけの短命なプログラムです。プログラム終了時に確保されているメモリはOSによってすべて自動的に解放されます。

### 単項
- 単項演算子: unary operator
- 2項演算子: binary operator

### cmp, ZF
```
  pop rdi
  pop rax
  cmp rax, rdi
  sete al
  movzb rax, al
```
```cmp rax, rdi```による比較結果 -> ZF
ZF: 同じだったら1, 違ったら0
```sete``` -> ZFが1なら指定されたレジスタに1を入れる(それ以外は0)

#### al
> ALというのは本書のここまでに登場していない新しいレジスタ名ですが、実は**ALはRAXの下位8ビットを指す別名レジスタ**にすぎません。
従ってseteが**ALに値をセットすると、自動的にRAXも更新される**ことになります。
ただし、RAXをAL経由で更新するときに上位56ビットは元の値のままになるので、RAX全体を0か1にセットしたい場合、上位56ビットはゼロクリアする必要があります。それを行うのがmovzb命令です。sete命令が直接RAXに書き込めればよいのですが、**seteは8ビットレジスタしか引数に取れない仕様になっているので、比較命令では、このように2つの命令を使ってRAXに値をセットすることになります**。


### 分割コンパイル
>分割コンパイルとは、1つのプログラムを複数のソースファイルに分割して書いて、別々にコンパイルすることです。分割コンパイルでは、コンパイラはプログラム全体ではなく、プログラムの断片を読んで、それに対応した断片を出力することになります。単体では**実行不可能なプログラムの断片の入ったファイルのことを「オブジェクトファイル」（拡張子は.o）といいます**。分割コンパイルでは、最後にオブジェクトファイルをつなぎ合わせて1つのファイルを作ることになります。オブジェクトファイルをまとめて1つの実行ファイルにするプログラムのことを「リンカ」といいます。
>
>なぜ分割コンパイルをする必要があるのかを理解しておきましょう。実は、**技術的にはソースを分割しなければならない必然性というものはありません**。コンパイラにソースコードを一度に全部渡せば、コンパイラはリンカの助けなしに完全な実行ファイルを出力することが論理的には可能です。
>
>ただしそのようなやり方の場合、コンパイラは、プログラムが使っているコードを本当にすべて知っている必要があります。例えばprintfなどの標準ライブラリの関数は、普通は標準ライブラリの作者がCで書いた関数なわけですが、**リンクのステップを省くためには、そういった関数のソースコードも毎回コンパイラの入力に与える必要が出てきてしまいます**。何度も同じ関数をコンパイルするのは、多くの場合、単なる時間の無駄です。したがって**標準ライブラリは普通はコンパイル済みのオブジェクトファイル形式で配布されていて、手元で毎回コンパイルし直さなくてよくなっています**。つまり、1つのソースコードからなるプログラムでも、標準ライブラリを使っている限り、実は分割コンパイルを利用しているのです。
>
>分割コンパイルを行わないと、1行変更しただけでもコード全体をコンパイルし直すことになります。数万行の長さのコードではコンパイルは数十秒はかかります。大きなプロジェクトではソースコードは1000万行以上あったりするので、それを1つの単位としてコンパイルすると1日では終わらないでしょう。メモリも100GiBといった単位で必要になります。そういったビルド手順は非現実的です。

### ヘッダファイル, include
> 分割コンパイルでは、コンパイラはプログラムの一部分のコードだけを見ることになりますが、コンパイラはプログラムのどのような小さな断片でもコンパイルできるというわけではありません。例えば次のコードを考えてみてください。
```.c
  void print_bar(struct Foo *obj) {
    printf("%d\n", obj->bar);
  }
```
> 上記のコードでは、構造体Fooの型を知っていればこのコードに対応するアセンブリを出力することができますが、そうでなければこの関数をコンパイルすることはできません。

> コンパイラが出力する関数呼び出しのコードは、引数をある決められた順番でレジスタにセットして、call命令を使って別の関数の先頭にジャンプします。引数の型によっては整数を浮動小数点数に変換するといったことも行います。引数の型や個数が間違っている場合はエラーメッセージを表示する必要もあります。したがって**関数の引数の個数や個々の引数の型**が必要です。
>
> 呼び出した関数の先で何が行われていても、呼び出し元にとってはそのうち単にリターンしてくるだけなので、**呼び出し先の関数のコードは、呼び出し元の関数をコンパイルするときには必要ありません**。
>
> callで飛ぶ先のアドレスは分割コンパイル時にはわかりませんが、アセンブラはとりあえずアドレス0にジャンプするようなcall命令を出力しておいて、オブジェクトファイル内に「オブジェクトファイルのXバイト目をYという名前の関数のアドレスで修正する」という情報を残しておくことができます。リンカはその情報を見て、実行ファイルのレイアウトを決めた後、プログラム断片をバイナリパッチングして、ジャンプ先のアドレスを修正します（この操作を「リロケートする」といいます）。したがって、分割コンパイルするためには**関数の名前は必要ですが、関数のアドレスは不要**です。

↓

プロトタイプ宣言

#### From ChatGPT
>C言語におけるヘッダファイルは、関数や変数の宣言、定数の定義、型の定義などを含むテキストファイルです。主な目的は、関数や変数を他のソースファイルで共有し、コンパイル時に必要な情報を提供することです。
>
>ヘッダファイルの主な意味や利点は以下の通りです:
>
> 1. 関数と変数の宣言: ヘッダファイルでは、関数と変数のプロトタイプ（prototype）を宣言することができます。これにより、関数や変数の存在と型が他のソースファイルに伝えられ、関数や変数を使用する際にコンパイラが正しい呼び出しや参照を確認できます。
>
> 2. 型の定義: ヘッダファイルでは、新しい型の定義を行うことができます。構造体（struct）、共用体（union）、列挙型（enum）などのカスタムデータ型をヘッダファイルで定義することで、異なるソースファイルで同じ型を使用できます。
>
> 3. マクロや定数の定義: ヘッダファイルでは、マクロや定数の定義を行うことができます。コード内で使用される定数値や条件付きコンパイルをサポートするための条件付きコンパイルディレクティブ（例: #ifdef、#ifndef）もヘッダファイルに含めることができます。
> 
> 4. コードの再利用とモジュール化: ヘッダファイルを使用することで、関数やデータをモジュール化し、コードの再利用性を高めることができます。複数のソースファイルで同じヘッダファイルをインクルードすることで、共通のコードを簡単に利用できます。
>
>ヘッダファイルは、プログラムの可読性、メンテナンス性、再利用性を向上させるために重要な役割を果たします。関数や変数の宣言や定義をヘッダファイルにまとめることで、コードの組織化やモジュール化が容易になります。また、大規模なプロジェクトでは、関連するヘッダファイルの作成と適切なインクルードによって、コンパイル時間を節約することもできます。

#### include

> Cでは、このように他のCファイルをコンパイルするときに必要になる宣言をまとめて、ヘッダファイル（拡張子は.h）というものに書くことになっています。foo.hに宣言を書いておいて、それを必要とする別のCファイルに#include "foo.h"のように書いておくと、#includeの行がfoo.hファイルの内容に置き換えられることになります

>ここまでの分割コンパイルの話を踏まえると、「printfを使うときは#include <stdio.h>をおまじないとして書いておきます」といった話が、実際には何をしているのかがわかると思います。**C標準ライブラリはリンカに暗黙のうちに渡される**ので、リンカはprintfの関数呼び出しが含まれたオブジェクトファイルをリンクして実行ファイルを作成することができます。一方で、**コンパイラはprintfについてはデフォルトでは特に知識を持っていません**。printfは組み込み関数ではなく、標準ライブラリのヘッダファイルが自動的に読み込まれるといった仕様も存在しないので、起動した直後はコンパイラはprintfについては何も知らない状態です。この状態から、C標準ライブラリについてくる**ヘッダファイルをインクルードすることで、printfの存在とその型をコンパイラは知ることができ**、printfの関数呼び出しをコンパイルできるようになるのです。

#### how to link

https://stackoverflow.com/questions/15441877/how-do-i-link-object-files-in-c-fails-with-undefined-symbols-for-architecture

https://www.cs.uaf.edu/2006/fall/cs301/lecture/12_04_linker.html

### グローバル変数
> 我々のコンパイラにはまだグローバル変数がないので、グローバル変数に対応するアセンブリの例というのはまだ出ていませんが、**グローバル変数というものはアセンブリレベルでは関数とほとんど同じ**です。したがって関数と同様に、グローバル変数にも定義と宣言の区別があります。変数の本体が複数のCファイルに重複して存在している場合、通常それはリンクエラーになります。

> グローバル変数はデフォルトでは実行禁止メモリ領域に割り付けられるので、そこにジャンプするとプログラムがセグメンテーションフォールトでクラッシュすることになりますが、本質的にはそれ以外、データとコードの違いは存在しません。**<font color=red>実行時に関数をデータとしてグローバル変数のように読むこともできますし、実行を許可するようにメモリの属性を変更してデータにジャンプすれば、データをコードとして実行することもできます</font>**。

**関数**と**グローバル変数**がどちらも本質的にはメモリ上に存在するデータにすぎない

↓

```.c
  char main[] = "\x48\xc7\xc0\x2a\x00\x00\x00\xc3";
```
これはデータだが、コードとして実行することもできる(関数をデータとして扱えるってこういうこと？(javascriptとか))

### Makefile
```Makefile
CFLAGS=-std=c11 -g -static
SRCS=$(wildcard *.c)
OBJS=$(SRCS:.c=.o)

9cc: $(OBJS)
        $(CC) -o 9cc $(OBJS) $(LDFLAGS)

$(OBJS): 9cc.h

test: 9cc
        ./test.sh

clean:
        rm -f 9cc *.o *~ tmp*

.PHONY: test clean
```
- ```概説```: Makefileでは、コロンで区切られた行と、タブでインデントされた0行以上のコマンドの行が、1つのルールを構成します。コロンの前の名前のことを「ターゲット」といいます。コロンの後ろの0個以上のファイル名のことを依存ファイルといいます。
- ```.PHONY```: ダミーのターゲットを表すための特別な名前です。make testやmake cleanは、testやcleanといったファイルを作成するために実行するわけではないのですが、普通はmakeにはそのことがわからないので、testやcleanといった名前のファイルが偶然存在している場合、make testやmake cleanは何も行わなくなってしまいます。こういったダミーのターゲットは、.PHONYで指定することにより、本当にそういう名前のファイルを作りたいわけではなく、指定されたターゲットのファイルが存在しているかどうかに関わらずルールのコマンドを実行するべきということをmakeに伝えることができます。
- ```CC```: compilerの指定(何も指定しない場合は```cc```になる)
    - https://stackoverflow.com/questions/2965829/what-does-cc-in-a-makefile-mean
- ```CFLAGS```: makeの組み込みルールによって認識される変数で、Cコンパイラに渡すコマンドラインオプションを書いておきます。
- ```SRCS(sources?)```: sourceファイルを記述する
    - ```SRCS = main.c foo.c bar.c```こんな感じで描ける
    - ```SRCS=$(wildcard *.c)```<- これだと```*.c```
- ```OBJS```: コンパイル結果のオブジェクトファイル
    - ```OBJS=$(SRCS:.c=.o)```この書き方だと```.c```がついているcのファイルをそれぞれ```.o```がつくオブジェクトファイルにコンパイルする
- **makeコマンドに引数を指定しない場合**
    - 1番上のターゲットが実行される
    - -> ```make 9cc```と同値
- ```$(OBJS): 9cc.h```
    - すべての.oファイルが9cc.hに依存していることを表しています。したがって9cc.hを変更した場合、すべての.oファイルが再コンパイルされることになります。



https://zenn.dev/yagiyuki/articles/b5545c3b546bbeb662bf

### 関数とローカル変数
#### スタック上の変数領域

> Cにおける変数はメモリ上に存在します。**変数はメモリのアドレスに名前をつけたもの**と言ってもよいでしょう。メモリアドレスに名前をつけることにで、「メモリの0x6080番地にアクセスする」というように表現するのではなく、「変数aにアクセスする」というように表現することができるようになります。

> ただし、関数のローカル変数は、関数呼び出しごとに別々に存在しなければいけません。実装の都合だけを考えると、例えば「関数fのローカル変数aは0x6080番地に置く」というようにアドレスを決め打ちにしてしまうのが簡単そうですが、それだとfを再帰的に呼び出した場合にうまく動きません。ローカル変数を関数呼び出しごとに別々に持たせるために、Cではローカル変数はスタックに置くことになっています。

↓

スタックフレームが出てくる

- rsp & rbp

9ccは式の途中の計算結果をRSPを使ったスタックにプッシュ／ポップしているので、RSPの値は頻繁に変更されます。したがって、aやbにはRSPからの**固定のオフセットでアクセスすることができません**。

↓

rbpが出てくる
> これを解決するための一般的なやり方では、RSPとは別に、現在の関数フレームの開始位置を常に指しているレジスタを用意します。そのようなレジスタを「ベースレジスタ」、そこに入っている値のことを「ベースポインタ」と呼びます。x86-64では慣習としてRBPレジスタをベースレジスタとして使用します。

- prologue, epilogueについて(全く逆のことをやってる <=> 元に戻る)
    - https://qiita.com/tobira-code/items/75d3034aed8bb9828981#function-prologue

### 変数とパーサ
識別子 -> 終端記号

> 変数というのは数値が使えるところではどこでも使えるので、numだったところをnum | identというようにすると、数値と同じ場所で変数が使える文法になります。
>
>それに加えて、文法に代入式を足す必要があります。変数は代入できないと仕方がないので、a=1のような式を許す文法にしたいというわけです。ここではCにあわせて、a=b=1のように書ける文法にしておきましょう。
